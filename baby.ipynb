{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1MmHVVFCsN2UehicsIL2HIg2cTnXO4qyd",
      "authorship_tag": "ABX9TyMlq/44Ghg0wee5lKrhHyi4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohiteYash/baby/blob/main/baby.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDm06WckGG-K",
        "outputId": "b5136aec-782f-47aa-8fa3-cf1cf8bb363a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape: (365, 128, 128, 1)\n",
            "y_train shape: (365, 5)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
        "\n",
        "# Define Constants\n",
        "DATASET_PATH = r'/content/drive/MyDrive/Baby_dataset/Baby_crying _Dataset'\n",
        "IMG_SIZE = (128, 128)  # Mel spectrogram size\n",
        "num_classes = 5  # Categories: belly pain, burping, discomfort, hungry, tired\n",
        "\n",
        "# Function to Convert Audio to Fixed-Size Mel Spectrogram\n",
        "def extract_spectrogram(file_path, img_size=IMG_SIZE):\n",
        "    y, sr = librosa.load(file_path, sr=22050)\n",
        "    mel_spec = librosa.feature.melspectrogram(y=y, sr=sr, n_mels=128, fmax=8000)\n",
        "    mel_spec_db = librosa.power_to_db(mel_spec, ref=np.max)  # Convert to dB scale\n",
        "\n",
        "    # Ensure fixed width (truncate or pad)\n",
        "    if mel_spec_db.shape[1] < img_size[1]:\n",
        "        # Pad with zeros if shorter\n",
        "        pad_width = img_size[1] - mel_spec_db.shape[1]\n",
        "        mel_spec_db = np.pad(mel_spec_db, ((0, 0), (0, pad_width)), mode='constant')\n",
        "    else:\n",
        "        # Truncate if longer\n",
        "        mel_spec_db = mel_spec_db[:, :img_size[1]]\n",
        "\n",
        "    mel_spec_db = np.expand_dims(mel_spec_db, axis=-1)  # Add channel dimension\n",
        "    return mel_spec_db\n",
        "\n",
        "# Load Dataset\n",
        "X, y = [], []\n",
        "for label in os.listdir(DATASET_PATH):\n",
        "    label_path = os.path.join(DATASET_PATH, label)\n",
        "    if os.path.isdir(label_path):\n",
        "        for file in os.listdir(label_path):\n",
        "            if file.endswith(\".wav\"):\n",
        "                file_path = os.path.join(label_path, file)\n",
        "                spectrogram = extract_spectrogram(file_path)\n",
        "                X.append(spectrogram)\n",
        "                y.append(label)\n",
        "\n",
        "# Convert to NumPy Arrays\n",
        "X = np.array(X)  # ✅ All spectrograms are now (128,128,1)\n",
        "y = np.array(y)\n",
        "\n",
        "# Encode Labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)  # Convert labels to integers\n",
        "y = to_categorical(y, num_classes=num_classes)  # One-hot encode\n",
        "\n",
        "# Split Data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "# Reshape for CNN Input\n",
        "X_train = X_train.reshape(X_train.shape[0], IMG_SIZE[0], IMG_SIZE[1], 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], IMG_SIZE[0], IMG_SIZE[1], 1)\n",
        "\n",
        "# Verify Shapes\n",
        "print(\"X_train shape:\", X_train.shape)  # Expected: (num_samples, 128, 128, 1)\n",
        "print(\"y_train shape:\", y_train.shape)  # Expected: (num_samples, 5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CNN Model\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE[0], IMG_SIZE[1], 1)),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D((2, 2)),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(256, activation='relu'),\n",
        "    Dropout(0.3),\n",
        "    Dense(num_classes, activation='softmax')  # Output layer for classification\n",
        "])\n",
        "\n",
        "# Compile the Model\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the Model\n",
        "history = model.fit(X_train, y_train, epochs=40, batch_size=32, validation_data=(X_test, y_test))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tx5Tnjc0G1ZS",
        "outputId": "c03f23e4-8a2c-43f6-f2b1-c00fcfcc91bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 357ms/step - accuracy: 0.5634 - loss: 17.1446 - val_accuracy: 0.8370 - val_loss: 0.7513\n",
            "Epoch 2/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 29ms/step - accuracy: 0.8332 - loss: 0.7424 - val_accuracy: 0.8370 - val_loss: 0.8863\n",
            "Epoch 3/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8239 - loss: 0.8778 - val_accuracy: 0.8370 - val_loss: 1.0726\n",
            "Epoch 4/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8381 - loss: 0.8606 - val_accuracy: 0.8370 - val_loss: 0.7784\n",
            "Epoch 5/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8235 - loss: 0.8730 - val_accuracy: 0.8370 - val_loss: 0.7480\n",
            "Epoch 6/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8341 - loss: 0.7432 - val_accuracy: 0.8370 - val_loss: 0.6707\n",
            "Epoch 7/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8275 - loss: 0.7606 - val_accuracy: 0.8370 - val_loss: 0.6473\n",
            "Epoch 8/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8211 - loss: 0.7330 - val_accuracy: 0.8370 - val_loss: 0.6482\n",
            "Epoch 9/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8399 - loss: 0.6787 - val_accuracy: 0.8370 - val_loss: 0.6734\n",
            "Epoch 10/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8378 - loss: 0.6789 - val_accuracy: 0.8370 - val_loss: 0.6516\n",
            "Epoch 11/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8265 - loss: 0.7104 - val_accuracy: 0.8370 - val_loss: 0.6443\n",
            "Epoch 12/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8253 - loss: 0.6827 - val_accuracy: 0.8370 - val_loss: 0.6526\n",
            "Epoch 13/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8637 - loss: 0.5627 - val_accuracy: 0.8370 - val_loss: 0.7067\n",
            "Epoch 14/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8267 - loss: 0.6909 - val_accuracy: 0.8370 - val_loss: 0.6606\n",
            "Epoch 15/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8356 - loss: 0.6453 - val_accuracy: 0.8370 - val_loss: 0.6746\n",
            "Epoch 16/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8609 - loss: 0.6152 - val_accuracy: 0.8370 - val_loss: 0.7068\n",
            "Epoch 17/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8100 - loss: 0.7346 - val_accuracy: 0.8370 - val_loss: 0.6440\n",
            "Epoch 18/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8234 - loss: 0.7149 - val_accuracy: 0.8370 - val_loss: 0.6685\n",
            "Epoch 19/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8350 - loss: 0.6296 - val_accuracy: 0.8370 - val_loss: 0.6398\n",
            "Epoch 20/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8444 - loss: 0.6117 - val_accuracy: 0.8370 - val_loss: 0.6497\n",
            "Epoch 21/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8261 - loss: 0.6748 - val_accuracy: 0.8370 - val_loss: 0.6481\n",
            "Epoch 22/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8158 - loss: 0.7313 - val_accuracy: 0.8370 - val_loss: 0.6315\n",
            "Epoch 23/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8309 - loss: 0.6488 - val_accuracy: 0.8370 - val_loss: 0.6365\n",
            "Epoch 24/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8152 - loss: 0.6486 - val_accuracy: 0.8370 - val_loss: 0.7359\n",
            "Epoch 25/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8386 - loss: 0.6509 - val_accuracy: 0.8370 - val_loss: 0.6546\n",
            "Epoch 26/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8281 - loss: 0.6657 - val_accuracy: 0.8370 - val_loss: 0.6406\n",
            "Epoch 27/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8312 - loss: 0.5904 - val_accuracy: 0.8370 - val_loss: 0.6617\n",
            "Epoch 28/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8504 - loss: 0.4877 - val_accuracy: 0.8261 - val_loss: 0.7628\n",
            "Epoch 29/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8529 - loss: 0.4868 - val_accuracy: 0.8261 - val_loss: 0.9478\n",
            "Epoch 30/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8658 - loss: 0.4436 - val_accuracy: 0.8261 - val_loss: 0.9539\n",
            "Epoch 31/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8821 - loss: 0.4152 - val_accuracy: 0.8152 - val_loss: 0.9654\n",
            "Epoch 32/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9155 - loss: 0.2981 - val_accuracy: 0.7717 - val_loss: 1.8400\n",
            "Epoch 33/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9117 - loss: 0.3075 - val_accuracy: 0.8043 - val_loss: 1.1753\n",
            "Epoch 34/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9112 - loss: 0.3019 - val_accuracy: 0.8043 - val_loss: 1.8118\n",
            "Epoch 35/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9306 - loss: 0.2278 - val_accuracy: 0.7500 - val_loss: 1.4302\n",
            "Epoch 36/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9230 - loss: 0.2629 - val_accuracy: 0.8152 - val_loss: 1.7589\n",
            "Epoch 37/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9258 - loss: 0.2024 - val_accuracy: 0.7065 - val_loss: 1.5796\n",
            "Epoch 38/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9422 - loss: 0.1940 - val_accuracy: 0.7609 - val_loss: 2.4971\n",
            "Epoch 39/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.9399 - loss: 0.1992 - val_accuracy: 0.7935 - val_loss: 2.5999\n",
            "Epoch 40/40\n",
            "\u001b[1m12/12\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9388 - loss: 0.1758 - val_accuracy: 0.7500 - val_loss: 1.5906\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate Model\n",
        "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Accuracy: {test_acc * 100:.2f}%\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJZl93dkG1eM",
        "outputId": "c51e0e77-2afe-4a40-b6d4-1f023485b906"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7422 - loss: 1.6043\n",
            "Test Accuracy: 75.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the Model\n",
        "\n",
        "model.save(\"baby_cry_cnn_model.h5\")\n",
        "\n",
        "# Load the Model\n",
        "loaded_model = tf.keras.models.load_model(\"baby_cry_cnn_model.h5\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8uYJaczHCPw",
        "outputId": "130ee5fe-ac0c-4cdf-d7fa-8b81574f8e33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to Predict Baby Cry Reason\n",
        "def predict_cry_reason(file_path, model):\n",
        "    spectrogram = extract_spectrogram(file_path)\n",
        "    spectrogram = spectrogram.reshape(1, IMG_SIZE[0], IMG_SIZE[1], 1)  # Reshape for model input\n",
        "    prediction = model.predict(spectrogram)\n",
        "    predicted_label = label_encoder.inverse_transform([np.argmax(prediction)])\n",
        "    return predicted_label[0]\n",
        "\n",
        "# Example Prediction\n",
        "sample_file = \"/content/drive/MyDrive/Baby_dataset/Baby_crying _Dataset/tired/5B416CE8-2591-4531-9ADC-86D085B5D48B-1430144827-1.0-m-48-ti.wav\"  # Update with a test file\n",
        "predicted_reason = predict_cry_reason(sample_file, loaded_model)\n",
        "print(f\"Predicted Baby Cry Reason: {predicted_reason}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0m-f-7oIFIT",
        "outputId": "e5a437c6-f8a2-4878-82bf-0063759cec77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
            "Predicted Baby Cry Reason: tired\n"
          ]
        }
      ]
    }
  ]
}